{"cells":[{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-12-19T03:41:37.301637Z","iopub.status.busy":"2022-12-19T03:41:37.301186Z","iopub.status.idle":"2022-12-19T03:41:37.311990Z","shell.execute_reply":"2022-12-19T03:41:37.310670Z","shell.execute_reply.started":"2022-12-19T03:41:37.301589Z"},"id":"GjMfcSoJUF1Z","trusted":true},"outputs":[],"source":["#Device check and load model into device\n","def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","    \n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl: \n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-12-19T03:41:37.314656Z","iopub.status.busy":"2022-12-19T03:41:37.314087Z","iopub.status.idle":"2022-12-19T03:41:46.578539Z","shell.execute_reply":"2022-12-19T03:41:46.577296Z","shell.execute_reply.started":"2022-12-19T03:41:37.314588Z"},"id":"l0mdeQHgUF1b","outputId":"b660fd79-5409-4303-810c-e1547b467630","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: thop in /opt/conda/lib/python3.7/site-packages (0.1.1.post2209072238)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from thop) (1.11.0)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->thop) (4.1.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["! pip install thop"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":123,"referenced_widgets":["36104332d74c47b5848504ff751a5840","23d37bd07fed43149a55e382e5c341dd","e9dd77fda6474b58864f3f4bd86364bd","2db52c4e121147e8856ecb046d163338","4b01f72a314342848c3d03d60fb571f9","671cecab495a44409156fdf0e9449f71","2a6270152ebc46e7bac9831d3395c1c1","672d9653cde74e1ca0a2c3dd9f538430","8ad3d692909943288be91163a554afe8","043995c03de44e039d8f40ef85932d4a","de5bdeda5654457e93ef00a31ae183ce"]},"execution":{"iopub.execute_input":"2022-12-19T03:41:46.581704Z","iopub.status.busy":"2022-12-19T03:41:46.581256Z","iopub.status.idle":"2022-12-19T03:41:58.028840Z","shell.execute_reply":"2022-12-19T03:41:58.027823Z","shell.execute_reply.started":"2022-12-19T03:41:46.581662Z"},"id":"JRjWmTHyUF1c","outputId":"cedcfc38-22c4-4941-d2d1-aaa4d3065754","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["import pandas as pd\n","import os\n","import torch\n","import time\n","import torchvision\n","import torch.nn as nn\n","import numpy as np\n","import torch.nn.functional as F\n","from torchvision.datasets.utils import download_url\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as tt\n","from torch.utils.data import random_split\n","from torchvision.utils import make_grid\n","import torchvision.models as models\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import *\n","\n","\n","##HYPER-PARAM\n","batch_size = 200\n","epochs = 120\n","max_lr = 0.001\n","grad_clip = 0.01\n","weight_decay =0.001\n","opt_func = torch.optim.Adam\n","\n","##DOWNLOAD dataset\n","train_data = torchvision.datasets.CIFAR100('./', train=True, download=True)\n","# Stick all the images together to form a 1600000 X 32 X 3 array\n","x = np.concatenate([np.asarray(train_data[i][0]) for i in range(len(train_data))])\n","# calculate the mean and std along the (0, 1) axes\n","mean = np.mean(x, axis=(0, 1))/255\n","std = np.std(x, axis=(0, 1))/255\n","# the the mean and std\n","mean=mean.tolist()\n","std=std.tolist()\n","\n","#随机遮挡：\n","class Cutout(object):\n","    \"\"\"Randomly mask out one or more patches from an image.\n","    Args:\n","        n_holes (int): Number of patches to cut out of each image.\n","        length (int): The length (in pixels) of each square patch.\n","    \"\"\"\n","    def __init__(self, n_holes, length):\n","        self.n_holes = n_holes\n","        self.length = length\n","\n","    def __call__(self, img):\n","        \"\"\"\n","        Args:\n","            img (Tensor): Tensor image of size (C, H, W).\n","        Returns:\n","            Tensor: Image with n_holes of dimension length x length cut out of it.\n","        \"\"\"\n","        h = img.size(1)\n","        w = img.size(2)\n","\n","        mask = np.ones((h, w), np.float32)\n","\n","        for n in range(self.n_holes):\n","        \t# (x,y)表示方形补丁的中心位置\n","            y = np.random.randint(h)\n","            x = np.random.randint(w)\n","\n","            y1 = np.clip(y - self.length // 2, 0, h)\n","            y2 = np.clip(y + self.length // 2, 0, h)\n","            x1 = np.clip(x - self.length // 2, 0, w)\n","            x2 = np.clip(x + self.length // 2, 0, w)\n","\n","            mask[y1: y2, x1: x2] = 0.\n","\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img = img * mask\n","\n","        return img\n","\n","##TRANSFORM\n","transform_train = tt.Compose([tt.RandomCrop(32, padding=4,padding_mode='reflect'), \n","                         tt.RandomHorizontalFlip(), \n","                         tt.ToTensor(), \n","                         tt.Normalize(mean,std,inplace=True),\n","                         Cutout(n_holes=1, length=16)])\n","transform_test = tt.Compose([tt.ToTensor(), tt.Normalize(mean,std)])\n","##DATASET and DATALOADER\n","trainset = torchvision.datasets.CIFAR100(\"./\",\n","                                         train=True,\n","                                         download=True,\n","                                         transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(\n","    trainset, batch_size, shuffle=True, num_workers=2,pin_memory=True)\n","\n","testset = torchvision.datasets.CIFAR100(\"./\",\n","                                        train=False,\n","                                        download=True,\n","                                        transform=transform_test)\n","testloader = torch.utils.data.DataLoader(\n","    testset, batch_size*2,pin_memory=True, num_workers=2)\n","#LOADER\n","device = get_default_device()\n","trainloader = DeviceDataLoader(trainloader, device)\n","testloader = DeviceDataLoader(testloader, device)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-12-19T03:41:58.031867Z","iopub.status.busy":"2022-12-19T03:41:58.030280Z","iopub.status.idle":"2022-12-19T03:41:58.037119Z","shell.execute_reply":"2022-12-19T03:41:58.036097Z","shell.execute_reply.started":"2022-12-19T03:41:58.031825Z"},"id":"C-vqbaVlUF1f","trusted":true},"outputs":[],"source":["cuda = torch.cuda.is_available()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-12-19T03:41:58.040565Z","iopub.status.busy":"2022-12-19T03:41:58.039891Z","iopub.status.idle":"2022-12-19T03:41:58.051614Z","shell.execute_reply":"2022-12-19T03:41:58.050644Z","shell.execute_reply.started":"2022-12-19T03:41:58.040526Z"},"id":"9Dfi8N-LUF1g","trusted":true},"outputs":[],"source":["##TRAINING SETUP\n","def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n","\n","class ImageClassificationBase(nn.Module):\n","    def training_step(self, batch):\n","        images, labels = batch \n","        out = self(images)                  # Generate predictions\n","        loss = F.cross_entropy(out, labels) # Calculate loss\n","        return loss\n","    \n","    def validation_step(self, batch):\n","        images, labels = batch \n","        out = self(images)                    # Generate predictions\n","        loss = F.cross_entropy(out, labels)   # Calculate loss\n","        acc = accuracy(out, labels)           # Calculate accuracy\n","        return {'val_loss': loss.detach(), 'val_acc': acc}\n","        \n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        batch_accs = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n","    \n","    def epoch_end(self, epoch, result):\n","        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-12-19T03:41:58.053899Z","iopub.status.busy":"2022-12-19T03:41:58.053117Z","iopub.status.idle":"2022-12-19T03:41:58.066203Z","shell.execute_reply":"2022-12-19T03:41:58.065153Z","shell.execute_reply.started":"2022-12-19T03:41:58.053861Z"},"id":"WSKr78p3UF1h","trusted":true},"outputs":[],"source":["class BasicConv2d(nn.Module):\n","\n","  def __init__(self, in_channels, out_channels, **kwargs):\n","    super(BasicConv2d, self).__init__()\n","    self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n","    self.bn = nn.BatchNorm2d(out_channels)\n","\n","  def forward(self, x):\n","    x = self.conv(x)\n","    x = self.bn(x)\n","    #使用silu激活函数替代relu\n","    return F.silu(x, inplace=True)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-12-19T03:41:58.068452Z","iopub.status.busy":"2022-12-19T03:41:58.067896Z","iopub.status.idle":"2022-12-19T03:41:58.121989Z","shell.execute_reply":"2022-12-19T03:41:58.121019Z","shell.execute_reply.started":"2022-12-19T03:41:58.068416Z"},"id":"C9pmyzwrUF1h","trusted":true},"outputs":[],"source":["class Inception3(ImageClassificationBase):\n","  def __init__(self, num_classes=100):\n","    super().__init__()\n","    \n","    self.Conv2d_1a_3x3 = BasicConv2d(3, 32, kernel_size=3, stride=1)\n","    self.Conv2d_2b_3x3 = BasicConv2d(32, 64, kernel_size=3, padding=1)\n","    self.Conv2d_3b_1x1 = BasicConv2d(64, 128, kernel_size=1)\n","    self.Conv2d_4a_3x3 = BasicConv2d(128, 192, kernel_size=3)\n","    self.Mixed_5b = InceptionA(192, pool_features=16)\n","    self.Mixed_5c = InceptionA(256, pool_features=48)\n","    self.Mixed_5d = InceptionA(288, pool_features=48)\n","    self.Mixed_6a = InceptionB(288)\n","    self.fc = nn.Sequential(nn.Linear(2032, 512),nn.Linear(512,num_classes))\n","    \n","  def forward(self, x):\n","    #先进行四层卷积\n","    x = self.Conv2d_1a_3x3(x)\n","    x = self.Conv2d_2b_3x3(x)\n","    x = self.Conv2d_3b_1x1(x)\n","    x = self.Conv2d_4a_3x3(x)\n","    #使用inceptionA模块训练三次\n","    x = F.max_pool2d(x, kernel_size=3, stride=2)\n","    x = self.Mixed_5b(x)\n","    x = self.Mixed_5c(x)\n","    x = self.Mixed_5d(x)\n","    #使用inceptionB模块训练一次\n","    x = self.Mixed_6a(x)\n","    x = F.max_pool2d(x, kernel_size=3, stride=2)\n","    x = F.dropout(x, p=0.1, training=self.training)\n","    x = torch.flatten(x, 1)\n","    x = self.fc(x)\n","    return x\n","\n","\n","class InceptionA(ImageClassificationBase):\n","  def __init__(self, in_channels, pool_features):\n","    super().__init__()\n","    self.branch1x1 = BasicConv2d(in_channels, 64, kernel_size=1)\n","    \n","    self.branch5x5_1 = BasicConv2d(in_channels, 32, kernel_size=1)\n","    self.branch5x5_2 = BasicConv2d(32, 64, kernel_size=5, padding=2)\n","    \n","    self.branch3x3dbl_1 = BasicConv2d(in_channels, 32, kernel_size=1)\n","    self.branch3x3dbl_2 = BasicConv2d(32, 112, kernel_size=3, padding=1)\n","    \n","    self.branch_pool = BasicConv2d(in_channels, pool_features, kernel_size=1)\n","\n","  def forward(self, x):\n","    #第一支路：1*1卷积核压缩通道数\n","    branch1x1 = self.branch1x1(x)\n","    #第二支路：1*1卷积核压缩通道数\n","    #        5*5卷积核获取特征\n","    branch5x5 = self.branch5x5_1(x)\n","    branch5x5 = self.branch5x5_2(branch5x5)\n","    #第三支路：1*1卷积核压缩通道数\n","    #        3*3卷积核获取特征\n","    branch3x3dbl = self.branch3x3dbl_1(x)\n","    branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n","    #第四支路：承接最大池化步骤，1*1卷积核提取特征\n","    branch_pool = F.max_pool2d(x, kernel_size=3, stride=1, padding=1)\n","    branch_pool = self.branch_pool(branch_pool)\n","\n","    outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n","    return torch.cat(outputs, 1)\n","\n","\n","class InceptionB(ImageClassificationBase):\n","\n","  def __init__(self, in_channels):\n","    super(InceptionB, self).__init__()\n","    self.branch1x1 = BasicConv2d(in_channels, 64, kernel_size=1)\n","    self.branch3x3 = BasicConv2d(64, 124, kernel_size=3, stride=2)\n","    \n","    self.branch3x3dbl_1 = BasicConv2d(in_channels, 32, kernel_size=1)\n","    self.branch3x3dbl_2 = BasicConv2d(32, 96, kernel_size=3, stride=2)\n","\n","  def forward(self, x):\n","    #第一支路：1*1卷积核压缩通道数\n","    #        3*3卷积核提取特征\n","    branch1x1 = self.branch1x1(x)\n","    branch3x3 = self.branch3x3(branch1x1)\n","    #第二支路：1*1卷积核压缩通道数\n","    #        3*3卷积核提取特征\n","    branch3x3dbl = self.branch3x3dbl_1(x)\n","    branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n","    #第三支路：最大池化\n","    branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n","\n","    outputs = [branch3x3, branch3x3dbl, branch_pool]\n","    return torch.cat(outputs, 1)\n","\n","model = Inception3().cuda()"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-12-19T03:41:58.123899Z","iopub.status.busy":"2022-12-19T03:41:58.123452Z","iopub.status.idle":"2022-12-19T03:42:32.294893Z","shell.execute_reply":"2022-12-19T03:42:32.293553Z","shell.execute_reply.started":"2022-12-19T03:41:58.123864Z"},"id":"clNdM6BMUxHh","trusted":true},"outputs":[],"source":["###########mixup:\n","alpha = 1.0  # 默认设置为1\n","criterion = nn.CrossEntropyLoss()\n","for (inputs, labels) in trainloader:\n","    lam = np.random.beta(alpha, alpha)\n","    index = torch.randperm(inputs.size(0))\n","    images_a, images_b = inputs, inputs[index]\n","    labels_a, labels_b = labels, labels[index]\n","    mixed_images = lam * images_a + (1 - lam) * images_b\n","    outputs = model(mixed_images)\n","    _, preds = torch.max(outputs, 1)\n","    loss = lam * criterion(outputs, labels_a) + (1 - lam) * criterion(outputs, labels_b)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-12-19T03:42:32.297837Z","iopub.status.busy":"2022-12-19T03:42:32.297376Z","iopub.status.idle":"2022-12-19T03:42:32.311243Z","shell.execute_reply":"2022-12-19T03:42:32.309918Z","shell.execute_reply.started":"2022-12-19T03:42:32.297798Z"},"id":"0KKRBA4uUF1i","trusted":true},"outputs":[],"source":["#Training Setup\n","@torch.no_grad()\n","def evaluate(model, test_loader):\n","    model.eval()\n","    outputs = [model.validation_step(batch) for batch in test_loader]\n","    return model.validation_epoch_end(outputs)\n","\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","\n","def fit_one_cycle(epochs, max_lr, model, train_loader, test_loader, \n","                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n","    torch.cuda.empty_cache()\n","    history = []\n","    \n","    # Set up cutom optimizer with weight decay\n","    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n","    # Set up one-cycle learning rate scheduler\n","    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n","                                                steps_per_epoch=len(train_loader))\n","    \n","    for epoch in range(epochs):\n","        # Training Phase \n","        model.train()\n","        train_losses = []\n","        lrs = []\n","        for batch in train_loader:\n","            loss = model.training_step(batch)\n","            train_losses.append(loss)\n","            loss.backward()\n","            \n","            # Gradient clipping\n","            if grad_clip: \n","                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n","            \n","            optimizer.step()\n","            optimizer.zero_grad()\n","            \n","            # Record & update learning rate\n","            lrs.append(get_lr(optimizer))\n","            sched.step()\n","        \n","        # Validation phase\n","        result = evaluate(model, test_loader)\n","        result['train_loss'] = torch.stack(train_losses).mean().item()\n","        result['lrs'] = lrs\n","        model.epoch_end(epoch, result)\n","        history.append(result)\n","    return history"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-12-19T03:42:32.313515Z","iopub.status.busy":"2022-12-19T03:42:32.313072Z","iopub.status.idle":"2022-12-19T05:26:53.137778Z","shell.execute_reply":"2022-12-19T05:26:53.136456Z","shell.execute_reply.started":"2022-12-19T03:42:32.313480Z"},"id":"rXIT8ffOUF1i","outputId":"cee43c1d-a1e6-41d8-cd3c-1f112644898a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [0], last_lr: 0.00003, train_loss: 4.2964, val_loss: 3.8880, val_acc: 0.1268\n","Epoch [1], last_lr: 0.00004, train_loss: 3.8093, val_loss: 3.4850, val_acc: 0.1778\n","Epoch [2], last_lr: 0.00005, train_loss: 3.5319, val_loss: 3.2623, val_acc: 0.2087\n","Epoch [3], last_lr: 0.00006, train_loss: 3.3373, val_loss: 3.0281, val_acc: 0.2566\n","Epoch [4], last_lr: 0.00007, train_loss: 3.1578, val_loss: 2.8604, val_acc: 0.2873\n","Epoch [5], last_lr: 0.00008, train_loss: 2.9971, val_loss: 2.6836, val_acc: 0.3127\n","Epoch [6], last_lr: 0.00010, train_loss: 2.8491, val_loss: 2.5179, val_acc: 0.3525\n","Epoch [7], last_lr: 0.00012, train_loss: 2.7277, val_loss: 2.4143, val_acc: 0.3756\n","Epoch [8], last_lr: 0.00014, train_loss: 2.6279, val_loss: 2.3467, val_acc: 0.3922\n","Epoch [9], last_lr: 0.00017, train_loss: 2.5346, val_loss: 2.2307, val_acc: 0.4141\n","Epoch [10], last_lr: 0.00020, train_loss: 2.4287, val_loss: 2.1793, val_acc: 0.4283\n","Epoch [11], last_lr: 0.00022, train_loss: 2.3508, val_loss: 2.0609, val_acc: 0.4538\n","Epoch [12], last_lr: 0.00025, train_loss: 2.2736, val_loss: 1.9773, val_acc: 0.4753\n","Epoch [13], last_lr: 0.00028, train_loss: 2.1941, val_loss: 1.9423, val_acc: 0.4834\n","Epoch [14], last_lr: 0.00032, train_loss: 2.1601, val_loss: 1.8270, val_acc: 0.5080\n","Epoch [15], last_lr: 0.00035, train_loss: 2.1004, val_loss: 1.8789, val_acc: 0.4982\n","Epoch [16], last_lr: 0.00038, train_loss: 2.0513, val_loss: 1.8471, val_acc: 0.5027\n","Epoch [17], last_lr: 0.00042, train_loss: 2.0055, val_loss: 1.8565, val_acc: 0.5065\n","Epoch [18], last_lr: 0.00045, train_loss: 1.9558, val_loss: 1.7597, val_acc: 0.5282\n","Epoch [19], last_lr: 0.00048, train_loss: 1.9288, val_loss: 1.8198, val_acc: 0.5114\n","Epoch [20], last_lr: 0.00052, train_loss: 1.9122, val_loss: 1.8574, val_acc: 0.4936\n","Epoch [21], last_lr: 0.00055, train_loss: 1.8741, val_loss: 1.6882, val_acc: 0.5372\n","Epoch [22], last_lr: 0.00058, train_loss: 1.8556, val_loss: 1.6011, val_acc: 0.5623\n","Epoch [23], last_lr: 0.00061, train_loss: 1.8217, val_loss: 1.6497, val_acc: 0.5506\n","Epoch [24], last_lr: 0.00064, train_loss: 1.8186, val_loss: 1.6261, val_acc: 0.5588\n","Epoch [25], last_lr: 0.00066, train_loss: 1.7988, val_loss: 1.6623, val_acc: 0.5482\n","Epoch [26], last_lr: 0.00069, train_loss: 1.7761, val_loss: 1.6172, val_acc: 0.5612\n","Epoch [27], last_lr: 0.00071, train_loss: 1.7470, val_loss: 1.6493, val_acc: 0.5580\n","Epoch [28], last_lr: 0.00073, train_loss: 1.7423, val_loss: 1.5340, val_acc: 0.5733\n","Epoch [29], last_lr: 0.00075, train_loss: 1.7263, val_loss: 1.5697, val_acc: 0.5714\n","Epoch [30], last_lr: 0.00076, train_loss: 1.7223, val_loss: 1.5690, val_acc: 0.5706\n","Epoch [31], last_lr: 0.00078, train_loss: 1.6968, val_loss: 1.6175, val_acc: 0.5646\n","Epoch [32], last_lr: 0.00079, train_loss: 1.6997, val_loss: 1.5780, val_acc: 0.5719\n","Epoch [33], last_lr: 0.00079, train_loss: 1.6664, val_loss: 1.5382, val_acc: 0.5743\n","Epoch [34], last_lr: 0.00080, train_loss: 1.6679, val_loss: 1.5301, val_acc: 0.5767\n","Epoch [35], last_lr: 0.00080, train_loss: 1.6470, val_loss: 1.4886, val_acc: 0.5849\n","Epoch [36], last_lr: 0.00080, train_loss: 1.6410, val_loss: 1.5790, val_acc: 0.5781\n","Epoch [37], last_lr: 0.00080, train_loss: 1.6228, val_loss: 1.5328, val_acc: 0.5766\n","Epoch [38], last_lr: 0.00080, train_loss: 1.6150, val_loss: 1.4737, val_acc: 0.5945\n","Epoch [39], last_lr: 0.00080, train_loss: 1.5976, val_loss: 1.4976, val_acc: 0.5850\n","Epoch [40], last_lr: 0.00079, train_loss: 1.5929, val_loss: 1.5134, val_acc: 0.5804\n","Epoch [41], last_lr: 0.00079, train_loss: 1.5837, val_loss: 1.4420, val_acc: 0.5936\n","Epoch [42], last_lr: 0.00079, train_loss: 1.5614, val_loss: 1.4287, val_acc: 0.5983\n","Epoch [43], last_lr: 0.00078, train_loss: 1.5693, val_loss: 1.4268, val_acc: 0.6059\n","Epoch [47], last_lr: 0.00076, train_loss: 1.5230, val_loss: 1.4237, val_acc: 0.6049\n","Epoch [48], last_lr: 0.00075, train_loss: 1.5156, val_loss: 1.4381, val_acc: 0.6078\n","Epoch [49], last_lr: 0.00075, train_loss: 1.5031, val_loss: 1.4203, val_acc: 0.6116\n","Epoch [50], last_lr: 0.00074, train_loss: 1.4952, val_loss: 1.3822, val_acc: 0.6203\n","Epoch [51], last_lr: 0.00073, train_loss: 1.4893, val_loss: 1.5233, val_acc: 0.5821\n","Epoch [52], last_lr: 0.00072, train_loss: 1.4805, val_loss: 1.3702, val_acc: 0.6233\n","Epoch [53], last_lr: 0.00071, train_loss: 1.4554, val_loss: 1.4055, val_acc: 0.6154\n","Epoch [54], last_lr: 0.00070, train_loss: 1.4605, val_loss: 1.3557, val_acc: 0.6224\n","Epoch [55], last_lr: 0.00069, train_loss: 1.4337, val_loss: 1.3785, val_acc: 0.6250\n","Epoch [56], last_lr: 0.00068, train_loss: 1.4264, val_loss: 1.2950, val_acc: 0.6296\n","Epoch [57], last_lr: 0.00067, train_loss: 1.4314, val_loss: 1.3482, val_acc: 0.6238\n","Epoch [58], last_lr: 0.00066, train_loss: 1.4154, val_loss: 1.3029, val_acc: 0.6331\n","Epoch [59], last_lr: 0.00065, train_loss: 1.4043, val_loss: 1.3640, val_acc: 0.6294\n","Epoch [60], last_lr: 0.00064, train_loss: 1.3962, val_loss: 1.3173, val_acc: 0.6318\n","Epoch [61], last_lr: 0.00063, train_loss: 1.3873, val_loss: 1.3017, val_acc: 0.6346\n","Epoch [62], last_lr: 0.00061, train_loss: 1.3757, val_loss: 1.3242, val_acc: 0.6347\n","Epoch [63], last_lr: 0.00060, train_loss: 1.3621, val_loss: 1.3688, val_acc: 0.6298\n","Epoch [64], last_lr: 0.00059, train_loss: 1.3525, val_loss: 1.2935, val_acc: 0.6457\n","Epoch [65], last_lr: 0.00057, train_loss: 1.3366, val_loss: 1.2807, val_acc: 0.6417\n","Epoch [66], last_lr: 0.00056, train_loss: 1.3246, val_loss: 1.3062, val_acc: 0.6373\n","Epoch [67], last_lr: 0.00055, train_loss: 1.3127, val_loss: 1.2295, val_acc: 0.6502\n","Epoch [68], last_lr: 0.00053, train_loss: 1.2980, val_loss: 1.2530, val_acc: 0.6579\n","Epoch [72], last_lr: 0.00047, train_loss: 1.2455, val_loss: 1.2415, val_acc: 0.6642\n","Epoch [73], last_lr: 0.00046, train_loss: 1.2316, val_loss: 1.1816, val_acc: 0.6665\n","Epoch [74], last_lr: 0.00044, train_loss: 1.2248, val_loss: 1.1740, val_acc: 0.6725\n","Epoch [75], last_lr: 0.00043, train_loss: 1.2001, val_loss: 1.1753, val_acc: 0.6727\n","Epoch [76], last_lr: 0.00041, train_loss: 1.1924, val_loss: 1.1654, val_acc: 0.6789\n","Epoch [77], last_lr: 0.00040, train_loss: 1.1832, val_loss: 1.1225, val_acc: 0.6835\n","Epoch [78], last_lr: 0.00039, train_loss: 1.1678, val_loss: 1.1755, val_acc: 0.6743\n","Epoch [79], last_lr: 0.00037, train_loss: 1.1532, val_loss: 1.1324, val_acc: 0.6825\n","Epoch [80], last_lr: 0.00036, train_loss: 1.1385, val_loss: 1.1756, val_acc: 0.6765\n","Epoch [81], last_lr: 0.00034, train_loss: 1.1171, val_loss: 1.1682, val_acc: 0.6725\n","Epoch [82], last_lr: 0.00033, train_loss: 1.0975, val_loss: 1.1328, val_acc: 0.6820\n","Epoch [83], last_lr: 0.00031, train_loss: 1.0822, val_loss: 1.1418, val_acc: 0.6811\n","Epoch [84], last_lr: 0.00030, train_loss: 1.0669, val_loss: 1.1135, val_acc: 0.6894\n","Epoch [85], last_lr: 0.00028, train_loss: 1.0590, val_loss: 1.1290, val_acc: 0.6911\n","Epoch [86], last_lr: 0.00027, train_loss: 1.0426, val_loss: 1.0771, val_acc: 0.6961\n","Epoch [87], last_lr: 0.00025, train_loss: 1.0231, val_loss: 1.0576, val_acc: 0.7034\n","Epoch [88], last_lr: 0.00024, train_loss: 1.0103, val_loss: 1.0904, val_acc: 0.6986\n","Epoch [89], last_lr: 0.00023, train_loss: 0.9870, val_loss: 1.0392, val_acc: 0.6988\n","Epoch [90], last_lr: 0.00021, train_loss: 0.9757, val_loss: 1.0681, val_acc: 0.7033\n","Epoch [91], last_lr: 0.00020, train_loss: 0.9606, val_loss: 1.0703, val_acc: 0.7033\n","Epoch [92], last_lr: 0.00019, train_loss: 0.9378, val_loss: 1.0397, val_acc: 0.7104\n","Epoch [93], last_lr: 0.00017, train_loss: 0.9270, val_loss: 1.0407, val_acc: 0.7073\n","Epoch [94], last_lr: 0.00016, train_loss: 0.9106, val_loss: 1.0370, val_acc: 0.7047\n","Epoch [95], last_lr: 0.00015, train_loss: 0.8987, val_loss: 1.0176, val_acc: 0.7169\n","Epoch [96], last_lr: 0.00014, train_loss: 0.8741, val_loss: 0.9979, val_acc: 0.7177\n","Epoch [97], last_lr: 0.00013, train_loss: 0.8583, val_loss: 0.9984, val_acc: 0.7185\n","Epoch [98], last_lr: 0.00012, train_loss: 0.8594, val_loss: 0.9998, val_acc: 0.7258\n","Epoch [99], last_lr: 0.00011, train_loss: 0.8395, val_loss: 0.9832, val_acc: 0.7247\n","Epoch [100], last_lr: 0.00010, train_loss: 0.8340, val_loss: 1.0000, val_acc: 0.7243\n","Epoch [101], last_lr: 0.00009, train_loss: 0.8111, val_loss: 0.9875, val_acc: 0.7267\n","Epoch [102], last_lr: 0.00008, train_loss: 0.8032, val_loss: 0.9776, val_acc: 0.7264\n","Epoch [103], last_lr: 0.00007, train_loss: 0.7904, val_loss: 0.9836, val_acc: 0.7256\n","Epoch [104], last_lr: 0.00006, train_loss: 0.7761, val_loss: 0.9782, val_acc: 0.7273\n","Epoch [105], last_lr: 0.00005, train_loss: 0.7714, val_loss: 0.9716, val_acc: 0.7313\n","Epoch [108], last_lr: 0.00003, train_loss: 0.7391, val_loss: 0.9607, val_acc: 0.7357\n","Epoch [109], last_lr: 0.00003, train_loss: 0.7336, val_loss: 0.9597, val_acc: 0.7367\n","Epoch [110], last_lr: 0.00002, train_loss: 0.7212, val_loss: 0.9574, val_acc: 0.7369\n","Epoch [111], last_lr: 0.00002, train_loss: 0.7206, val_loss: 0.9508, val_acc: 0.7384\n","Epoch [112], last_lr: 0.00001, train_loss: 0.7133, val_loss: 0.9481, val_acc: 0.7397\n","Epoch [113], last_lr: 0.00001, train_loss: 0.6977, val_loss: 0.9497, val_acc: 0.7376\n","Epoch [114], last_lr: 0.00001, train_loss: 0.7022, val_loss: 0.9490, val_acc: 0.7381\n","Epoch [115], last_lr: 0.00000, train_loss: 0.7011, val_loss: 0.9486, val_acc: 0.7396\n","Epoch [116], last_lr: 0.00000, train_loss: 0.6971, val_loss: 0.9502, val_acc: 0.7393\n","Epoch [117], last_lr: 0.00000, train_loss: 0.7018, val_loss: 0.9457, val_acc: 0.7387\n","Epoch [118], last_lr: 0.00000, train_loss: 0.6923, val_loss: 0.9493, val_acc: 0.7393\n","Epoch [119], last_lr: 0.00000, train_loss: 0.6938, val_loss: 0.9465, val_acc: 0.7376\n","Training time: 6257.46 s\n"]}],"source":["#max_lr = 0.001\n","#Training(Using Multi_LR)\n","history = [evaluate(model, testloader)] ## Initial evaluation\n","# Fitting the first 1/4 \n","current_time=time.time()\n","history += fit_one_cycle(120, 0.0008, model, trainloader, testloader, \n","                             grad_clip=grad_clip, \n","                             weight_decay=weight_decay, \n","                             opt_func=opt_func)\n","'''\n","torch.save(model.state_dict(), 'group22_pretrained_model.h5')\n","# Fitting the first 2/4 epochs\n","history += fit_one_cycle(20, max_lr/50, model, trainloader, testloader, \n","                             grad_clip=grad_clip, \n","                             weight_decay=weight_decay, \n","                             opt_func=opt_func)\n","# Fitting the first 3/4 \n","history += fit_one_cycle(10, max_lr/100, model, trainloader, testloader, \n","                             grad_clip=grad_clip, \n","                             weight_decay=weight_decay, \n","                             opt_func=opt_func)\n","# Fitting the first 4/4 epochs\n","history += fit_one_cycle(10 , max_lr/100, model, trainloader, testloader, \n","                             grad_clip=grad_clip, \n","                             weight_decay=weight_decay, \n","                             opt_func=opt_func)\n","'''\n","# Print training time\n","time_train = time.time() - current_time\n","print('Training time: {:.2f} s'.format(time_train))"]},{"cell_type":"markdown","metadata":{"id":"-61xoQ96U9Uh"},"source":["# Fitting the first 3/4 \n","history += fit_one_cycle(int(epochs/6), max_lr/100, model, trainloader, testloader, \n","                             grad_clip=grad_clip, \n","                             weight_decay=weight_decay, \n","                             opt_func=opt_func)\n","# Fitting the first 4/4 epochs\n","history += fit_one_cycle(int(epochs/6), max_lr/100, model, trainloader, testloader, \n","                             grad_clip=grad_clip, \n","                             weight_decay=weight_decay, \n","                             opt_func=opt_func)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-12-19T05:26:53.141905Z","iopub.status.busy":"2022-12-19T05:26:53.141561Z","iopub.status.idle":"2022-12-19T05:26:56.868721Z","shell.execute_reply":"2022-12-19T05:26:56.867529Z","shell.execute_reply.started":"2022-12-19T05:26:53.141874Z"},"id":"uE3glLZXUF1k","outputId":"4ea0f0f6-2cba-496b-e8f9-ea1f17d2791f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Confusion matrix:\n","[[93  0  0 ...  0  0  0]\n"," [ 0 86  0 ...  0  0  0]\n"," [ 0  0 64 ...  0  3  0]\n"," ...\n"," [ 0  0  0 ... 82  0  0]\n"," [ 0  0  6 ...  0 57  0]\n"," [ 0  0  0 ...  0  0 70]]\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.93      0.92       100\n","           1       0.88      0.86      0.87       100\n","           2       0.64      0.64      0.64       100\n","           3       0.59      0.62      0.60       100\n","           4       0.61      0.60      0.60       100\n","           5       0.81      0.73      0.77       100\n","           6       0.79      0.79      0.79       100\n","           7       0.82      0.79      0.81       100\n","           8       0.92      0.90      0.91       100\n","           9       0.81      0.87      0.84       100\n","          10       0.57      0.60      0.59       100\n","          11       0.54      0.50      0.52       100\n","          12       0.78      0.77      0.77       100\n","          13       0.72      0.63      0.67       100\n","          14       0.86      0.74      0.80       100\n","          15       0.69      0.77      0.73       100\n","          16       0.69      0.72      0.71       100\n","          17       0.88      0.86      0.87       100\n","          18       0.66      0.72      0.69       100\n","          19       0.71      0.65      0.68       100\n","          20       0.85      0.82      0.84       100\n","          21       0.84      0.87      0.86       100\n","          22       0.76      0.81      0.78       100\n","          23       0.87      0.82      0.85       100\n","          24       0.87      0.83      0.85       100\n","          25       0.65      0.68      0.66       100\n","          26       0.63      0.67      0.65       100\n","          27       0.65      0.69      0.67       100\n","          28       0.80      0.81      0.81       100\n","          29       0.76      0.71      0.73       100\n","          30       0.66      0.69      0.68       100\n","          31       0.69      0.71      0.70       100\n","          32       0.62      0.62      0.62       100\n","          33       0.73      0.62      0.67       100\n","          34       0.84      0.78      0.81       100\n","          35       0.60      0.50      0.55       100\n","          36       0.84      0.82      0.83       100\n","          37       0.77      0.76      0.76       100\n","          38       0.59      0.64      0.62       100\n","          39       0.86      0.89      0.87       100\n","          40       0.64      0.64      0.64       100\n","          41       0.86      0.85      0.85       100\n","          42       0.72      0.81      0.76       100\n","          43       0.81      0.79      0.80       100\n","          44       0.51      0.48      0.49       100\n","          45       0.65      0.60      0.62       100\n","          46       0.50      0.53      0.51       100\n","          47       0.62      0.65      0.64       100\n","          48       0.89      0.96      0.92       100\n","          49       0.82      0.87      0.84       100\n","          50       0.63      0.64      0.63       100\n","          51       0.77      0.76      0.76       100\n","          52       0.59      0.67      0.63       100\n","          53       0.83      0.90      0.87       100\n","          54       0.80      0.89      0.84       100\n","          55       0.44      0.48      0.46       100\n","          56       0.92      0.87      0.89       100\n","          57       0.74      0.72      0.73       100\n","          58       0.87      0.85      0.86       100\n","          59       0.71      0.64      0.67       100\n","          60       0.87      0.86      0.86       100\n","          61       0.72      0.71      0.71       100\n","          62       0.74      0.82      0.78       100\n","          63       0.71      0.75      0.73       100\n","          64       0.73      0.59      0.65       100\n","          65       0.56      0.60      0.58       100\n","          66       0.84      0.83      0.83       100\n","          67       0.65      0.59      0.62       100\n","          68       0.89      0.92      0.91       100\n","          69       0.83      0.76      0.79       100\n","          70       0.78      0.76      0.77       100\n","          71       0.79      0.84      0.82       100\n","          72       0.52      0.55      0.54       100\n","          73       0.57      0.51      0.54       100\n","          74       0.48      0.54      0.51       100\n","          75       0.89      0.87      0.88       100\n","          76       0.89      0.92      0.91       100\n","          77       0.74      0.70      0.72       100\n","          78       0.57      0.62      0.59       100\n","          79       0.71      0.78      0.74       100\n","          80       0.66      0.52      0.58       100\n","          81       0.68      0.80      0.74       100\n","          82       0.94      0.93      0.93       100\n","          83       0.81      0.74      0.77       100\n","          84       0.73      0.72      0.73       100\n","          85       0.87      0.89      0.88       100\n","          86       0.83      0.77      0.80       100\n","          87       0.79      0.79      0.79       100\n","          88       0.88      0.81      0.84       100\n","          89       0.86      0.88      0.87       100\n","          90       0.76      0.83      0.79       100\n","          91       0.84      0.87      0.86       100\n","          92       0.74      0.64      0.68       100\n","          93       0.72      0.68      0.70       100\n","          94       0.90      0.92      0.91       100\n","          95       0.65      0.67      0.66       100\n","          96       0.69      0.66      0.67       100\n","          97       0.75      0.82      0.78       100\n","          98       0.55      0.57      0.56       100\n","          99       0.71      0.70      0.71       100\n","\n","    accuracy                           0.74     10000\n","   macro avg       0.74      0.74      0.74     10000\n","weighted avg       0.74      0.74      0.74     10000\n","\n","F1 score: 0.737417\n","Recall score: 0.737600\n","Accuracy score: 0.737600\n"]}],"source":["torch.save(model.state_dict(), 'group22_pretrained_model1.h5')\n","# Generate testing accuracy, predicted label, confusion matrix, and table for classification report\n","def test_label_predictions(model, device, test_loader):\n","    model.eval()\n","    actuals = []\n","    predictions = []\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            prediction = output.argmax(dim=1, keepdim=True)\n","            actuals.extend(target.view_as(prediction))\n","            predictions.extend(prediction)\n","    return [i.item() for i in actuals], [i.item() for i in predictions]\n","\n","y_test, y_pred = test_label_predictions(model, device, testloader)\n","cm=confusion_matrix(y_test, y_pred)\n","cr=classification_report(y_test, y_pred)\n","fs=f1_score(y_test,y_pred,average='weighted')\n","rs=recall_score(y_test, y_pred,average='weighted')\n","accuracy=accuracy_score(y_test, y_pred)\n","print('Confusion matrix:')\n","print(cm)\n","print(cr)\n","print('F1 score: %f' % fs)\n","print('Recall score: %f' % rs)\n","print('Accuracy score: %f' % accuracy)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-12-19T05:26:56.870498Z","iopub.status.busy":"2022-12-19T05:26:56.870094Z","iopub.status.idle":"2022-12-19T05:26:56.895806Z","shell.execute_reply":"2022-12-19T05:26:56.894946Z","shell.execute_reply.started":"2022-12-19T05:26:56.870458Z"},"id":"ka4D8VbLUF1k","outputId":"77d99d51-8905-4b90-a4bc-1dca303f68f6","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n","[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n","[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n","272840896.0\n","1846616.0\n"]}],"source":["### Paramater Size and FLOPS\n","from thop import profile\n","input = torch.randn(1, 3, 32, 32)\n","input = input.to(device)\n","flops, params = profile(model, inputs=(input,))\n","print(flops)\n","print(params)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]"},"vscode":{"interpreter":{"hash":"e19ad775cd04da04c4c8a4f45421f22340bc6f4bc27812f49788363657472ac0"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"043995c03de44e039d8f40ef85932d4a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23d37bd07fed43149a55e382e5c341dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_671cecab495a44409156fdf0e9449f71","placeholder":"​","style":"IPY_MODEL_2a6270152ebc46e7bac9831d3395c1c1","value":"100%"}},"2a6270152ebc46e7bac9831d3395c1c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2db52c4e121147e8856ecb046d163338":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_043995c03de44e039d8f40ef85932d4a","placeholder":"​","style":"IPY_MODEL_de5bdeda5654457e93ef00a31ae183ce","value":" 169001437/169001437 [00:03&lt;00:00, 54630475.86it/s]"}},"36104332d74c47b5848504ff751a5840":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_23d37bd07fed43149a55e382e5c341dd","IPY_MODEL_e9dd77fda6474b58864f3f4bd86364bd","IPY_MODEL_2db52c4e121147e8856ecb046d163338"],"layout":"IPY_MODEL_4b01f72a314342848c3d03d60fb571f9"}},"4b01f72a314342848c3d03d60fb571f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"671cecab495a44409156fdf0e9449f71":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"672d9653cde74e1ca0a2c3dd9f538430":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ad3d692909943288be91163a554afe8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"de5bdeda5654457e93ef00a31ae183ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9dd77fda6474b58864f3f4bd86364bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_672d9653cde74e1ca0a2c3dd9f538430","max":169001437,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8ad3d692909943288be91163a554afe8","value":169001437}}}}},"nbformat":4,"nbformat_minor":4}
